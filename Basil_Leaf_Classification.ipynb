{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basil Leaf Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chris300127/basil_leaf_project/blob/master/Basil_Leaf_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8QFZmUWqyQe",
        "colab_type": "code",
        "outputId": "82f177cf-9bc7-48d4-a92e-b2f6ec34ecf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np \n",
        "import sys\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#ML libraries\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTQKLC6vZpWP",
        "colab_type": "text"
      },
      "source": [
        "#### Number of images for each dataset\n",
        "- Healthy Basil: 148\n",
        "- Healthy Jamun: 279\n",
        "- Diseased Jamun: 345"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLBpl4mJte0R",
        "colab_type": "code",
        "outputId": "0398ba6c-4403-4843-c634-e2399cd7dd41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#load images from google drive\n",
        "\n",
        "def load_image(picNum=1, leaf_type='Basil',healthy=True, scale=0.1):\n",
        "  if picNum < 10:\n",
        "    picNum = f'00{picNum}'\n",
        "  elif picNum < 100:\n",
        "    picNum = f'0{picNum}'\n",
        "  \n",
        "  #leaf type\n",
        "  if leaf_type == 'Basil':\n",
        "    path=f'/content/drive/Shared drives/Senior Design/COEN/Photos/Online_Dataset/Basil (P8)/healthy/0008_0{picNum}.JPG'\n",
        "  elif leaf_type == 'Jamun':\n",
        "    if healthy:\n",
        "      path=f'/content/drive/Shared drives/Senior Design/COEN/Photos/Online_Dataset/Jamun (P5)/healthy/0005_0{picNum}.JPG'\n",
        "    else:\n",
        "      path=f'/content/drive/Shared drives/Senior Design/COEN/Photos/Online_Dataset/Jamun (P5)/diseased/0017_0{picNum}.JPG'\n",
        "  #read in and rescale   \n",
        "   #scale factor for each photo\n",
        "  img = cv2.imread(path)\n",
        "  width = int(img.shape[1] * scale)\n",
        "  height = int(img.shape[0] * scale)\n",
        "  dim=(width,height)\n",
        "\n",
        "  # resize image\n",
        "  return cv2.resize(img,dim,interpolation=cv2.INTER_AREA)\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPVg8W6rkqZk",
        "colab_type": "text"
      },
      "source": [
        "// Scaling it to the same size\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "// CNN (images as input)\n",
        "\n",
        "//SVM, PCA or LDA w/ kmean\n",
        "\n",
        "//https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWx8SdMKYZMs",
        "colab_type": "code",
        "outputId": "df2993ff-627c-41b8-f6f0-48fc2a4cfe5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#ML: Linear Discriminant Analysis\n",
        "#================================\n",
        "\n",
        "#load training data\n",
        "#-------------------\n",
        "training_pics = []\n",
        "training_health = []\n",
        "\n",
        "# will load 30 healthy and 30 diseased leaves into memory\n",
        "for i in range (1,31):\n",
        "  img = load_image(i,'Jamun',healthy=True)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  training_pics.append(img.flatten())\n",
        "  training_health.append('healthy')\n",
        "  img = load_image(i,'Jamun',healthy=False)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  training_pics.append(img.flatten())\n",
        "  training_health.append('diseased')\n",
        "\n",
        "training_pics = np.array(training_pics)\n",
        "training_health = np.array(training_health)\n",
        "print(\"Training Images Loaded\")\n",
        "# print(training_pics.shape,training_health.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Images Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyy8yXIfEOJS",
        "colab_type": "code",
        "outputId": "81b3a12f-bc1f-45d0-e683-8d84de8128f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create LDA Model from training images\n",
        "#------------------------------------\n",
        "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=False)\n",
        "lda.fit(training_pics, training_health)\n",
        "print(\"LDA Model Created\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LDA Model Created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgZhEM7fEbIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load testing images\n",
        "#-------------------\n",
        "testing_pics = []\n",
        "testing_health = []\n",
        "\n",
        "def load_testing(first_image, end_image):\n",
        "  global testing_pics, testing_health\n",
        "  testing_pics = []\n",
        "  testing_health = []\n",
        "\n",
        "  for j in range(first_image, end_image):\n",
        "    img = load_image(i,'Jamun',healthy=True)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    testing_pics.append(img.flatten())\n",
        "    testing_health.append('healthy')\n",
        "    img = load_image(i,'Jamun',healthy=False)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    testing_pics.append(img.flatten())\n",
        "    testing_health.append('diseased')\n",
        "\n",
        "  testing_pics = np.array(testing_pics)\n",
        "  testing_health = np.array(testing_health)\n",
        "  print(\"Testing Images Loaded\")\n",
        "  # print(testing_pics.shape,testing_health.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyKALBGqHsvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scoring data\n",
        "#-------------\n",
        "def score():\n",
        "  #score model with training original training data\n",
        "  score1 = lda.score(training_pics, training_health)\n",
        "  print(\"Training score:\",score1)\n",
        "\n",
        "  #score model with new testin data\n",
        "  score2 = lda.score(testing_pics, testing_health)\n",
        "  print(\"Testing score:\",score2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV9Xgj0BMEna",
        "colab_type": "code",
        "outputId": "eb77b070-a036-4582-8cf3-25d36786a6d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "load_testing(230,245)\n",
        "score()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Images Loaded\n",
            "Training score: 0.9166666666666666\n",
            "Testing score: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3cdGoven-7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# good_leaves = []  #will contain coordinates of good leaves\n",
        "\n",
        "\n",
        "def pixelsToInches(pixel):\n",
        "    return pixel * (18.6/640)\n",
        "\n",
        "\n",
        "def findLeaf(picNum=1):\n",
        "  sample = load_image(picNum)\n",
        "  gray = cv2.cvtColor(sample, cv2.COLOR_BGR2GRAY)\n",
        "  blurred = cv2.GaussianBlur(gray,(5,5),cv2.BORDER_DEFAULT)\n",
        "  canny = cv2.Canny(blurred,50,100)\n",
        "  kernel = np.ones((3,3),np.uint8)\n",
        "  dilate = cv2.dilate(canny, kernel, iterations=1)\n",
        "  cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnts = cnts[0] if len(cnts)==2 else cnts[1] #gets contours from tuple return value (which may be tuple of 2 or three depending on cv2 version)\n",
        "  # print(\"Number of leaves: \", len(cnts))\n",
        "  # LEAF_MUTEX.acquire()\n",
        "  display_image = sample #which image to display\n",
        "\n",
        "  max_area = 0\n",
        "  for c in cnts:\n",
        "    # c = cnts[0]\n",
        "    b_box = cv2.boundingRect(c)\n",
        "    #find largest b_box area\n",
        "    a = b_box[2]*b_box[3] #current bounding box area\n",
        "    if a > max_area:\n",
        "      max_area = a\n",
        "      x,y,w,h = b_box\n",
        "\n",
        "    \n",
        "  \n",
        "  \n",
        "  \n",
        "  cv2.rectangle(display_image, (x,y), (x+w, y+h), (36,255,12), 2)  #numbers specify color and width \n",
        "  # ROI = original[y:y+h, x:x+w]\n",
        "  r = 5\n",
        "  t = 1\n",
        "  cx = x + int(w / 2)\n",
        "  cy = y + int(h / 2)\n",
        "  cv2.circle(display_image, (cx, cy), r, (255, 0, 0), thickness=t)\n",
        "  \n",
        "  # print(pixelsToInches(x+cx),pixelsToInches(y+cy))\n",
        "  \n",
        "  if len(cnts)>0: #change from 0 to 1 to see potential errors\n",
        "    print(\"\\nImage\",picNum,\"- leaf found at:\",cx,cy)\n",
        "    cv2_imshow(display_image)\n",
        " \n",
        "\n",
        "\n",
        "  # Run extraction and ML\n",
        "  # should return bool if leaf is good or not good\n",
        "  # good = True\n",
        "  # if(good):\n",
        "  #   #insert into goodleaves\n",
        "  #   good_leaves.append((cx, cy))\n",
        "  # else:\n",
        "  #   pass\n",
        "  #   # discardLeaves()\n",
        "  # good_leaves.sort()\n",
        "\n",
        "  # LEAF_MUTEX.release()\n",
        "  # while True:\n",
        "  #   if cv2.waitKey(1)==27:  # esc key\n",
        "  #     break\n",
        "  # cap.release()\n",
        "  # cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "for i in range(1,280):\n",
        "  findLeaf(i)\n",
        "print(\"\\n\\nDone\\n\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i2WbKXn-qPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for i in range(1,149):\n",
        "  findLeaf(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_phWJAQ_Clse",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "###Basil Leaves\n",
        "- bounding boxes are a little off on image 45 & 70\n",
        "- all others are good\n",
        "\n",
        "\n",
        "###Jamun Leaves\n",
        "- Bounding box is off for images 14,20, & 198\n"
      ]
    }
  ]
}